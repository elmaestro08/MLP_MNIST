{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron code for Digit Classification\n",
    "\n",
    "The notebook walks through the MLP (Shallow Neural Network) with a hidden layer of size 1000 units and output layer of 10 units. The notebook provides the computational graph perspective of the MLP by implementing the forward propagation, cost function and backward propagation functions. \n",
    "\n",
    "The network is trained for 10 epochs with a random minibatch size of 5 on the training dataset of size 50,000 images. It is tested on the validation dataset of 10,000 images which achieved an accuracy of 92.73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset):\n",
    "    #Assumes mnist is downloaded and in the same path as this notebook\n",
    "    # Load the dataset\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        train_set, valid_set, test_set = u.load()\n",
    "    f.close()\n",
    "\n",
    "    Xtrain = np.array(train_set[0]).T\n",
    "    Ytrain = np.array(train_set[1])\n",
    "    Ytrain = Ytrain.reshape((1,Ytrain.shape[0]))\n",
    "    Xvalid = np.array(valid_set[0]).T\n",
    "    Yvalid = np.array(valid_set[1])\n",
    "    Yvalid = Yvalid.reshape((1, Yvalid.shape[0]))\n",
    "    Xtest = np.array(test_set[0]).T\n",
    "    Ytest = np.array(test_set[1])\n",
    "    Ytest = Ytest.reshape((1, Ytest.shape[0]))\n",
    "\n",
    "    return Xtrain, Ytrain, Xvalid, Yvalid, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 5, seed = 0):\n",
    "    '''\n",
    "    Parameters:   \n",
    "    X - Input data of size (n_x, m) \n",
    "    Y - True labels vector (1, m) \n",
    "    mini_batch_size - size of minibatches, integer \n",
    "    \n",
    "    Returns:\n",
    "    mini_batches - list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    '''\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "    \n",
    "    #Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))    #Randomly permute a sequence\n",
    "    shuffled_X = X[:, permutation]      #Shuffles examples column-wise\n",
    "    shuffled_Y = Y[:, permutation].reshape((1, m))\n",
    "    \n",
    "    #Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_batches = math.floor(m/mini_batch_size) #Number of mini batches of size mini_batch_size in your partioning.\n",
    "    for k in range(0, num_complete_batches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size: (k+1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size: (k+1) * mini_batch_size]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "        \n",
    "    #Handline the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        #end = m - mini_batch_size * math.floor(m / mini_batch_size)\n",
    "        mini_batch_X = shuffled_X[:, num_complete_batches * mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_batches * mini_batch_size:]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "        \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    n_x - size of input layer\n",
    "    n_h - size of hidden layer\n",
    "    n_y - size of output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "                \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    return np.exp(Z)/np.sum(np.exp(Z),axis = 0)  #A.shape = (n_y, m)\n",
    "    #return np.argmax(A,axis = 0).reshape(1, A.shape[1]) #Output shape = (1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    '''\n",
    "    Parameters:\n",
    "    X - Input data of size (n_x, m)\n",
    "    parameters - python dictionary containing the parameters of the model\n",
    "    \n",
    "    Returns:\n",
    "    A2 - The softmax output of the output layer activation\n",
    "    cache - a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    '''\n",
    "    \n",
    "    #Retrieve parameters from the dictionary parameters\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    #Forward propagation\n",
    "    Z1 = np.dot(W1,X) + b1\n",
    "    A1 = Z1\n",
    "    Z2 = np.dot(W2,A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2\n",
    "            }\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y):\n",
    "    '''\n",
    "    Parameters:\n",
    "    A2 - The activation of the output layer of size (n_y, m)\n",
    "    Y - True labels of size (1, m)\n",
    "    \n",
    "    Returns:\n",
    "    cost - cross entropy cost given parameters\n",
    "    '''\n",
    "    \n",
    "    #compute the cross entropy cost\n",
    "    m = Y.shape[1]\n",
    "    cost = -np.squeeze((np.sum(np.log(A2[Y,np.arange(A2.shape[1])]))))/m\n",
    "    \n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, cache, parameters):\n",
    "    '''\n",
    "    Parameters:\n",
    "    parameters - dictionary containing the parameters of the model\n",
    "    cache - dictionary containing 'Z1', 'A1', 'Z2', 'A2'\n",
    "    X - Input data of size (n_x, m)\n",
    "    Y - True labels of size (1, m)\n",
    "    \n",
    "    Returns:\n",
    "    grads - dictionary containing gradients w.r.t to different parameters\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    \n",
    "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
    "    Y = np.array([[1 if j == i else k for j, k in enumerate([0 for a in range(10)])] for i in Y.reshape(-1)]).T   #Converts the true label vectors from (1, m) to (n_y, m)\n",
    "    dZ2 = A2 - Y \n",
    "    dW2 = np.dot(dZ2, A1.T)/m\n",
    "    db2 = np.sum(dZ2, axis = 1, keepdims=True)/m\n",
    "    dZ1 = np.dot(W2.T, dZ2)/m\n",
    "    dW1 = np.dot(dZ1,X.T)/m\n",
    "    db1 = np.sum(dZ1, axis = 1, keepdims = True)/m\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2\n",
    "            }\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate = 0.01):\n",
    "    '''\n",
    "    Parameters:\n",
    "    parameters - dictionary containing parameters of the model\n",
    "    grads - dictionary containing gradients w.r.t. to the parameters of the model\n",
    "    \n",
    "    Returns:\n",
    "    parameters: dictionary containing updated parameters of the model\n",
    "    '''\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1,L+1):\n",
    "        parameters['W'+str(l)] = parameters['W'+str(l)] - learning_rate * grads['dW'+str(l)]\n",
    "        parameters['b'+str(l)] = parameters['b'+str(l)] - learning_rate * grads['db'+str(l)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(X, Y, num_iterations = 10, learning_rate=0.01, mini_batch_size = 5, print_cost = False):\n",
    "    '''\n",
    "    Parameters:\n",
    "    X - input data of size (n_x, m)\n",
    "    Y - True labels of size (1, m)\n",
    "    num_iterations - number of epochs for the training of the model\n",
    "    print_cost - if True print the cost for every 10 iterations\n",
    "    \n",
    "    Returns:\n",
    "    parameters - parameters learned by the model. They can be used to predict later.\n",
    "    '''\n",
    "    layers_dims = [X.shape[0], 1000, 10]\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        \n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size, 0)\n",
    "        \n",
    "        for minibatch in minibatches:\n",
    "            \n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "        \n",
    "            A2, cache = forward_propagation(minibatch_X, parameters)\n",
    "            \n",
    "            cost = compute_cost(A2, minibatch_Y)\n",
    "            \n",
    "            grads = backward_propagation(minibatch_X, minibatch_Y, cache, parameters)\n",
    "            \n",
    "            parameters = update_parameters(parameters, grads)\n",
    "            \n",
    "        if print_cost and i % 1 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 1 == 0:\n",
    "                print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    with open('model.pkl', 'wb') as handle:\n",
    "        pickle.dump(parameters, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                \n",
    "    return parameters \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    '''\n",
    "    Parameters:\n",
    "    parameters - dictionary containing the parameters of the model.\n",
    "    X - Input data of size (n_x, m)\n",
    "    \n",
    "    Returns:\n",
    "    predictions - vector of predictions of our model of size (1, m)\n",
    "    '''\n",
    "    \n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.argmax(A2, axis = 0).reshape(1, A2.shape[1])\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50000) (1, 50000) (784, 10000) (1, 10000) (784, 10000) (1, 10000)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain, Xvalid, Yvalid, Xtest, Ytest = load_dataset('mnist.pkl.gz')\n",
    "print(Xtrain.shape, Ytrain.shape,Xvalid.shape, Yvalid.shape, Xtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.020517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 1: 0.015128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 2: 0.015050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 3: 0.015258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 4: 0.015324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 5: 0.015268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 6: 0.015131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 7: 0.014945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 8: 0.014727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 9: 0.014492\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = mlp(Xtrain, Ytrain, num_iterations=10, learning_rate=0.01, mini_batch_size= 5, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(Xvalid, Yvalid, parameters):\n",
    "\n",
    "    test_loss, test_acc, test_count = 0,0,0\n",
    "\n",
    "    predictions = predict(parameters, Xvalid)\n",
    "    \n",
    "    test_acc += np.sum(predictions == Yvalid)\n",
    "    \n",
    "    #test_loss = test_loss / test_count\n",
    "    test_acc = test_acc / Xvalid.shape[1]\n",
    "\n",
    "    print('\\nTest Accuracy = ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTest Accuracy = 0.9273\n"
     ]
    }
   ],
   "source": [
    "with open('model.pkl', 'rb') as handle:\n",
    "    parameters = pickle.load(handle)\n",
    "test(Xvalid, Yvalid, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
